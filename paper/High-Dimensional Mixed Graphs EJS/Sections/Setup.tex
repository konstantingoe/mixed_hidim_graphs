To numerically assess the accuracy of our mixed graph estimation approach, we commence with a simulation study in which the estimators are rigorously evaluated in a gold-standard fashion and compared against oracles.
\paragraph{Simulation strategy.}
To enable a comprehensive comparison, we adopt a data-generating strategy akin to that of \cite{Fan17}. Our experiments unfold in two parts. First, we investigate the binary mixed case, benchmarking our approach against scenarios c) and d) in Section 6.1 of \cite{Fan17}. Second, we consider the general mixed case where the discrete variables are allowed to have arbitrarily many levels. In this case, we compare our approach to the ensemble approach by \cite{Feng19}.

% Subsequently, we generate a combination of binary-ternary-continuous data. Despite the absence of numerical results in the simulation study by \citet{Quan18}, we compare our approach with their extension of \citet{Fan17}. In the third part, we generate discrete data with varying levels from $\mathbf{Z}$ and assess performance against\todo{the ensemble estimator proposed by \cite{Feng19}} the latent continuous oracle.

% For detailed results and a comprehensive description of the simulation setup for binary-ternary-continuous data simulations, refer to Section 6\todo{Move this setup from the appendix to the plain text.} of the Supplementary Materials.


At the outset, we construct the underlying precision matrix $\mathbf{\Omega}^*$. We set $\mathbf{\Omega}^*_{jj} = 1$ and $\mathbf{\Omega}_{jk}^* = s b_{jk}$ if $j\neq k$, where $s$ is the constant signal strength chosen to assure positive definiteness. Furthermore, $b_{jk}$ are realizations of a Bernoulli random variable with corresponding success probability $p_{jk} = (2\pi)^{-1/2} \exp\big[\Norm{v_j - v_k}_2 / (2c) \big]$. In particular, $v_j = (v_j^{(1)}, v_j^{(2)})$ are independent realizations of a bivariate uniform $[0,1]$ distribution and $c$ controls the sparsity of the graph.

Throughout the simulation, we set $s = 0.15$ and incrementally increase the dimensionality by $d= 50,250,750$, representing a transition from small to large-scale graphs. We let $\mathbf{\Sigma}^* = (\mathbf{\Omega}^*)^{-1}$ rescaled such that all diagonal elements are equal to $1$. Equipped with $\mathbf\Sigma^*$, we draw $n$ i.i.d. samples from $\text{NPN}_d(\mathbf{0}, \mathbf{\Sigma}^*, f)$ and set the back-transform \(f^{-1}\) accordingly.

In order to agree with the latent setup according to Definition 2.2
%\ref{def1}%
let $\mathbf{X}_1$ be partitioned into equally sized collections of binary, ordinal, and Poisson distributed random variables, i.e., $\mathbf{X}_1 = (\mathbf{X}_1^{\text{bin}}, \mathbf{X}_1^{\text{ord}},\mathbf{X}_1^{\text{pois}})$ where the generative procedure is according to Eq. (1) of the main Manuscript. %\eqref{latent_ordered}.

Recall that for any continuous random variable $X$ with corresponding cumulative distribution function (CDF) $F_X$, $Y \coloneqq F_X(X)$ is a standard uniformly distributed random variable. Then, given $Y$ and with the aid of the inverse probability integral transform, we can generate random samples from any cumulative distribution function \citep{Angus94}. Incidentally, this corresponds to the relationship described in Eq. (1) of the main Manuscript.
%\eqref{latent_ordered}. %
For $\mathbf{X}_1^{\text{bin}}$ the aforementioned transformation is employed with success probability drawn from Uniform$[0.4,0.6]$ for $80\%$ of $\mathbf{X}_1^{\text{bin}}$. The remaining $20\%$ mimics unbalanced classes, and success probability is drawn from Uniform$[0.05,0.1]$.

Regarding $\mathbf{X}_1^{\text{ord}}$, the inverse probability integral transform is used to generate samples from the multinomial distribution. To that end, the state space is drawn from Uniform$[3,10]$ and the corresponding probability of falling into one of these states is chosen to be proportional to the amount of states. Lastly, $\mathbf{X}_1^{\text{pois}}$ is generated with the inverse probability integral transform and the rate parameter set equal to $6$.


Throughout the experiments, $\hat{\Omega}$ is chosen by minimizing the eBIC according to the procedure outlined in Section \ref{sec:precision_matrix} with $\theta = 0.1$ for the low and medium, $\theta = 0.5$ for the high dimensional graphs.

We set the dimension to $d = (50, 250, 750)$ for sample size $n = (200, 200, 300)$ and choose $c$ such that the number of edges aligns roughly with the dimension -- except for $d = 50$, where we allow for $200$ edges following \citet{Fan17}.

\paragraph{Performance metrics.}
% To assess performance, we report the mean estimation error $\Norm{\hat{\mathbf{\Omega}} - \mathbf\Omega^*}_F$ as evaluated by the Frobenius norm. Furthermore, we consider graph recovery metrics. To this end, we define the number of true positives $\text{TP}(\lambda)$ and false positives $\text{FP}(\lambda)$ depending on the \textit{glasso path} as the number of nonzero lower off-diagonal elements that agree both in $\mathbf\Omega^*$ and $\hat{\mathbf\Omega}$ and the number of nonzero lower off-diagonal elements in $\hat{\mathbf\Omega}$ that are actually zero in $\mathbf\Omega^*$, respectively. The true positive rate $\text{TPR}(\lambda)$ and the false positive rate $\text{FPR}(\lambda)$ are defined as $\text{TPR} = \frac{\text{TP}(\lambda)}{\abs{E}} $ and $\text{FPR} = \frac{\text{FP}(\lambda)}{d(d-1)/2 - \abs{E}}$, respectively. Lastly, we consider the area under the curve (AUC) where a value of $0.5$ corresponds to random guessing of the presence of an edge and a value of $1$ corresponds to perfect error-free recovery of the underlying latent graph (in the rank sense of ROC analysis).
To evaluate performance, we report the mean estimation error $\Norm{\hat{\mathbf{\Omega}} - \mathbf\Omega^*}_F$ using the Frobenius norm. Additionally, we employ graph recovery metrics. For this purpose, we introduce the number of true positives $\text{TP}(\lambda)$ and false positives $\text{FP}(\lambda)$ based on the \textit{glasso path}. $\text{TP}(\lambda)$ represents the count of non-zero lower off-diagonal elements that are consistent both in $\mathbf\Omega^*$ and $\hat{\mathbf\Omega}$, while $\text{FP}(\lambda)$ denotes the count of non-zero lower off-diagonal elements in $\hat{\mathbf\Omega}$ that are actually zero in $\mathbf\Omega^*$.

The true positive rate $\text{TPR}(\lambda)$ and false positive rate $\text{FPR}(\lambda)$ are defined as $\text{TPR} = \frac{\text{TP}(\lambda)}{\abs{E}}$ and $\text{FPR} = \frac{\text{FP}(\lambda)}{d(d-1)/2 - \abs{E}}$, respectively.\todo{Adapt to table that is ending up in the paper.} Finally, we consider the area under the curve (AUC), where a value of $0.5$ corresponds to random guessing of edge presence and a value of $1$ indicates perfect error-free recovery of the underlying latent graph (in the rank sense of ROC analysis).